{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_N53zxDtLcI"
   },
   "source": [
    "First, mount your drive to give the notebook access to your Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "akEJID_wnMTc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ds9xP7rtnrZ"
   },
   "source": [
    "Next, change directory to wherever you created your folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkyXFsLGtvyc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Change this to your Drive folder location\n",
    "WORKING_DIRECTORY = '/content/drive/My Drive/Colab Notebooks/GateDetector/object_detection/data'\n",
    "os.chdir(WORKING_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43sPuLgxuemn"
   },
   "source": [
    "Now, let's install the Detecto package using pip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3-sRIuiuYDh"
   },
   "outputs": [],
   "source": [
    "!pip install detecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peLysju5vOgA"
   },
   "source": [
    "Import everything we need in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgJi8407uowH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from detecto import core\n",
    "from detecto import utils\n",
    "from detecto import visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCEC_0EQwLDf"
   },
   "source": [
    "How cute! Now, we're ready to create our dataset and train our model. However, before doing so, it's a bit awkward working with hundreds of individual XML label files, so we need to convert them into a single CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pnr8quRv8v7"
   },
   "outputs": [],
   "source": [
    "# Do this twice: once for our training labels and once for our validation labels\n",
    "utils.xml_to_csv('train_labels', 'train_labels.csv')\n",
    "utils.xml_to_csv('val_labels', 'test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csLF8GKQ3CGe"
   },
   "source": [
    "Below, we create our dataset, applying a couple of transforms beforehand. These are optional, but they can be useful for augmenting your dataset without gathering more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m7j17jxf31Gk"
   },
   "outputs": [],
   "source": [
    "# Specify a list of transformations for our dataset to apply on our images\n",
    "transform_img = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(800),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    utils.normalize_transform(),\n",
    "])\n",
    "\n",
    "dataset = core.Dataset('train_labels.csv', 'images/', transform=transform_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPFYk-lv6Cgd"
   },
   "source": [
    "Finally, let's train our model! We need to create a DataLoader over our dataset to specify how we feed the images into our model. We should also use our validation dataset to track the accuracy of the model throughout training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLRHugVo6kAt"
   },
   "outputs": [],
   "source": [
    "# Create our validation dataset\n",
    "val_dataset = core.Dataset('test_labels.csv', 'images/', transform=transform_img)\n",
    "\n",
    "# Create the loaders for our train and validation datasets\n",
    "loader = core.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "val_loader = core.DataLoader(val_dataset)\n",
    "\n",
    "# Create our model, passing in all unique classes we're predicting\n",
    "# Note: make sure these match exactly with the labels in the XML/CSV files!\n",
    "model = core.Model(['gate'])\n",
    "\n",
    "# Train the model! This step can take a while, so make sure you\n",
    "# the GPU is turned on in Edit -> Notebook settings\n",
    "losses = model.fit(loader, val_loader, epochs=30, learning_rate=0.01, gamma=0.2, lr_step_size=5, verbose=True)\n",
    "\n",
    "model.save('trained_model.pth')\n",
    "\n",
    "# Plot the accuracy over time\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvHbAcLb9cIL"
   },
   "outputs": [],
   "source": [
    "from detecto.visualize import plot_prediction_grid, detect_video\n",
    "\n",
    "detect_video(model, 'input.mp4', 'output.mp4')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Detecto.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
